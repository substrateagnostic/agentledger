#!/usr/bin/env npx ts-node
/**
 * AgentLedger Demo
 *
 * This demo shows how to use AgentLedger to create a tamper-evident audit trail
 * for AI agent operations. It demonstrates:
 *
 * 1. Setting up a ledger with compliance configurations
 * 2. Logging model calls, tool invocations, and decisions
 * 3. Verifying the audit log integrity
 * 4. Exporting to compliance formats
 *
 * Run with:
 *   npx ts-node examples/demo/index.ts
 *
 * Or with a real OpenAI API key:
 *   OPENAI_API_KEY=sk-... npx ts-node examples/demo/index.ts
 */

import { Ledger, hashContent, generateSigningKeys } from '../../packages/core/src';
import { writeFileSync } from 'fs';
import { join } from 'path';

// ============================================================================
// MOCK OPENAI CLIENT (used when no API key is set)
// ============================================================================

interface MockMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

interface MockCompletion {
  id: string;
  object: 'chat.completion';
  created: number;
  model: string;
  choices: Array<{
    index: number;
    message: { role: 'assistant'; content: string };
    finish_reason: 'stop';
  }>;
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

class MockOpenAI {
  private conversationHistory: MockMessage[] = [];

  async chat(messages: MockMessage[]): Promise<MockCompletion> {
    // Simulate network delay
    await new Promise(resolve => setTimeout(resolve, 200 + Math.random() * 300));

    // Store messages
    this.conversationHistory = messages;

    // Generate mock responses based on the last user message
    const lastUserMessage = [...messages].reverse().find(m => m.role === 'user')?.content || '';
    const response = this.generateResponse(lastUserMessage);

    const promptTokens = Math.ceil(JSON.stringify(messages).length / 4);
    const completionTokens = Math.ceil(response.length / 4);

    return {
      id: `mock-${Date.now()}`,
      object: 'chat.completion',
      created: Math.floor(Date.now() / 1000),
      model: 'gpt-4-mock',
      choices: [{
        index: 0,
        message: { role: 'assistant', content: response },
        finish_reason: 'stop',
      }],
      usage: {
        prompt_tokens: promptTokens,
        completion_tokens: completionTokens,
        total_tokens: promptTokens + completionTokens,
      },
    };
  }

  private generateResponse(userMessage: string): string {
    const lowerMessage = userMessage.toLowerCase();

    if (lowerMessage.includes('hello') || lowerMessage.includes('hi')) {
      return "Hello! I'm an AI assistant. I'm here to help you with any questions or tasks. What would you like to know about?";
    }

    if (lowerMessage.includes('weather')) {
      return "I can help you check the weather! For this demo, I'll simulate looking up the weather. It appears to be a pleasant 72¬∞F (22¬∞C) with partly cloudy skies. Would you like more details?";
    }

    if (lowerMessage.includes('summarize') || lowerMessage.includes('summary')) {
      return "I'd be happy to help summarize information. In this demo session, we've had a conversation where you asked about the weather, and I provided current conditions. Is there anything specific you'd like me to summarize?";
    }

    if (lowerMessage.includes('decision') || lowerMessage.includes('recommend')) {
      return "Based on my analysis, I would recommend Option A. This decision is based on the following factors: 1) Higher reliability, 2) Better cost-efficiency, 3) Faster implementation timeline. Would you like me to elaborate on any of these points?";
    }

    return "That's an interesting question! In this demo, I'm a mock AI that simulates responses. In a real deployment with an API key, you'd get actual AI-generated responses. Is there anything specific you'd like to explore?";
  }
}

// ============================================================================
// DEMO FUNCTIONS
// ============================================================================

async function runDemo(): Promise<void> {
  console.log('\nüîê AgentLedger Demo\n');
  console.log('‚ïê'.repeat(60) + '\n');

  // Check for OpenAI API key
  const hasApiKey = !!process.env.OPENAI_API_KEY;
  if (hasApiKey) {
    console.log('‚úì OpenAI API key detected - using real API\n');
  } else {
    console.log('! No OpenAI API key - using mock responses\n');
    console.log('  Set OPENAI_API_KEY to use real OpenAI API\n');
  }

  // Create signing keys for attestation
  console.log('üîë Generating signing keys...');
  const signingKeys = generateSigningKeys();
  console.log('   Keys generated successfully\n');

  // Initialize the ledger
  console.log('üìã Initializing audit ledger...');
  const ledger = new Ledger({
    orgId: 'demo-org',
    agentId: 'demo-agent',
    agentVersion: '1.0.0',
    environment: 'development',
    compliance: ['FINRA_4511', 'EU_AI_ACT'],
    retentionDays: 2555, // 7 years
    signingKeys,
    storage: 'memory',
  });

  // Start a new session
  const sessionId = await ledger.start(
    { type: 'user', identifier: 'demo-user' },
    { demo: true, timestamp: new Date().toISOString() }
  );
  console.log(`   Session ID: ${sessionId}\n`);

  // Initialize mock or real OpenAI client
  const mockClient = new MockOpenAI();

  // ============================================================================
  // TURN 1: Initial greeting
  // ============================================================================
  console.log('‚îÄ'.repeat(60));
  console.log('TURN 1: Initial Greeting');
  console.log('‚îÄ'.repeat(60) + '\n');

  const turn1Messages = [
    { role: 'system' as const, content: 'You are a helpful AI assistant. Be concise and friendly.' },
    { role: 'user' as const, content: 'Hello! Can you help me today?' },
  ];

  console.log('üë§ User: Hello! Can you help me today?\n');

  const startTime1 = Date.now();
  const response1 = await mockClient.chat(turn1Messages);
  const latency1 = Date.now() - startTime1;

  const response1Content = response1.choices[0]?.message.content ?? '';
  console.log(`ü§ñ Assistant: ${response1Content}\n`);

  // Log the model call
  await ledger.logModelCall({
    provider: 'openai',
    modelId: response1.model,
    parameters: { temperature: 0.7 },
    promptHash: hashContent(JSON.stringify(turn1Messages)),
    promptTokens: response1.usage.prompt_tokens,
    completionHash: hashContent(response1Content),
    completionTokens: response1.usage.completion_tokens,
    latencyMs: latency1,
    costUsd: response1.usage.total_tokens * 0.00003,
  });

  console.log(`   [Logged: ${response1.usage.total_tokens} tokens, ${latency1}ms]\n`);

  // ============================================================================
  // TURN 2: Tool use simulation
  // ============================================================================
  console.log('‚îÄ'.repeat(60));
  console.log('TURN 2: Weather Query (with simulated tool use)');
  console.log('‚îÄ'.repeat(60) + '\n');

  const turn2Messages = [
    ...turn1Messages,
    { role: 'assistant' as const, content: response1Content },
    { role: 'user' as const, content: "What's the weather like today?" },
  ];

  console.log("üë§ User: What's the weather like today?\n");

  // Log a decision point for choosing to use the weather tool
  await ledger.logDecision({
    decisionId: 'decision-weather-tool',
    category: 'tool_selection',
    optionsConsidered: [
      { option_id: 'weather_api', description: 'Use weather API tool', score: 0.9 },
      { option_id: 'direct_answer', description: 'Answer from knowledge', score: 0.3 },
    ],
    selectedOption: 'weather_api',
    reasoningHash: hashContent('User asked about weather, tool provides accurate real-time data'),
    confidenceScore: 0.9,
  });

  console.log('   [Decision logged: Selected weather_api tool]\n');

  // Simulate tool invocation
  const toolStart = Date.now();
  await new Promise(resolve => setTimeout(resolve, 100)); // Simulate API call
  const toolDuration = Date.now() - toolStart;

  await ledger.logToolInvocation({
    toolName: 'weather_api',
    inputHash: hashContent('location: current'),
    outputHash: hashContent('72¬∞F, partly cloudy'),
    durationMs: toolDuration,
    success: true,
    resourcesAccessed: [
      { type: 'api', identifier: 'weather.example.com', operation: 'read' },
    ],
  });

  console.log(`   [Tool logged: weather_api, ${toolDuration}ms]\n`);

  // Get the assistant's response
  const startTime2 = Date.now();
  const response2 = await mockClient.chat(turn2Messages);
  const latency2 = Date.now() - startTime2;

  const response2Content = response2.choices[0]?.message.content ?? '';
  console.log(`ü§ñ Assistant: ${response2Content}\n`);

  await ledger.logModelCall({
    provider: 'openai',
    modelId: response2.model,
    parameters: { temperature: 0.7 },
    promptHash: hashContent(JSON.stringify(turn2Messages)),
    promptTokens: response2.usage.prompt_tokens,
    completionHash: hashContent(response2Content),
    completionTokens: response2.usage.completion_tokens,
    latencyMs: latency2,
    costUsd: response2.usage.total_tokens * 0.00003,
  });

  console.log(`   [Logged: ${response2.usage.total_tokens} tokens, ${latency2}ms]\n`);

  // ============================================================================
  // TURN 3: Summary request
  // ============================================================================
  console.log('‚îÄ'.repeat(60));
  console.log('TURN 3: Conversation Summary');
  console.log('‚îÄ'.repeat(60) + '\n');

  const turn3Messages = [
    ...turn2Messages,
    { role: 'assistant' as const, content: response2Content },
    { role: 'user' as const, content: 'Can you summarize what we discussed?' },
  ];

  console.log('üë§ User: Can you summarize what we discussed?\n');

  const startTime3 = Date.now();
  const response3 = await mockClient.chat(turn3Messages);
  const latency3 = Date.now() - startTime3;

  const response3Content = response3.choices[0]?.message.content ?? '';
  console.log(`ü§ñ Assistant: ${response3Content}\n`);

  await ledger.logModelCall({
    provider: 'openai',
    modelId: response3.model,
    parameters: { temperature: 0.7 },
    promptHash: hashContent(JSON.stringify(turn3Messages)),
    promptTokens: response3.usage.prompt_tokens,
    completionHash: hashContent(response3Content),
    completionTokens: response3.usage.completion_tokens,
    latencyMs: latency3,
    costUsd: response3.usage.total_tokens * 0.00003,
  });

  console.log(`   [Logged: ${response3.usage.total_tokens} tokens, ${latency3}ms]\n`);

  // Take a state snapshot
  const totalTokens = response1.usage.total_tokens + response2.usage.total_tokens + response3.usage.total_tokens;
  const totalCost = totalTokens * 0.00003;
  await ledger.snapshot({
    trigger: 'manual',
    stateHash: hashContent(JSON.stringify({
      turns: 3,
      totalTokens,
    })),
    schemaVersion: '1.0.0',
    metrics: {
      total_tokens: totalTokens,
      total_cost_usd: totalCost,
      total_tool_calls: 1,
      total_decisions: 1,
      error_count: 0,
    },
  });

  // ============================================================================
  // VERIFICATION AND EXPORT
  // ============================================================================
  console.log('‚ïê'.repeat(60));
  console.log('VERIFICATION & EXPORT');
  console.log('‚ïê'.repeat(60) + '\n');

  // Verify the chain
  console.log('üîç Verifying audit log integrity...');
  const verification = await ledger.verify();
  if (verification.valid) {
    console.log('   ‚úì Hash chain verified\n');
  } else {
    console.log(`   ‚úó Verification failed: ${verification.errors.join(', ')}\n`);
  }

  // Get entry count
  const entryCount = await ledger.count();
  console.log(`üìä Total entries: ${entryCount}\n`);

  // Close the session and get the final log
  console.log('üì¶ Closing session and signing...');
  const auditLog = await ledger.close();
  console.log('   ‚úì Session closed');
  console.log(`   ‚úì Merkle root: ${(auditLog.merkle_root ?? '').substring(0, 16)}...`);
  console.log(`   ‚úì Signature: ${auditLog.org_signature ? 'Present' : 'None'}\n`);

  // Save the audit log
  const outputDir = join(__dirname, 'output');
  const logPath = join(outputDir, 'audit-log.json');

  try {
    await import('fs').then(fs => fs.mkdirSync(outputDir, { recursive: true }));
  } catch {}

  writeFileSync(logPath, JSON.stringify(auditLog, null, 2));
  console.log(`üíæ Saved audit log to: ${logPath}\n`);

  // Export to compliance formats
  console.log('üì§ Exporting to compliance formats...');

  const jsonlExport = await ledger.export({ format: 'jsonl' });
  writeFileSync(join(outputDir, 'audit.jsonl'), jsonlExport.toString());
  console.log('   ‚úì JSONL export');

  const finraExport = await ledger.export({ format: 'finra_4511' });
  writeFileSync(join(outputDir, 'audit.finra.json'), finraExport.toString());
  console.log('   ‚úì FINRA 4511 export');

  const euAiActExport = await ledger.export({ format: 'eu_ai_act' });
  writeFileSync(join(outputDir, 'audit.eu-ai-act.json'), euAiActExport.toString());
  console.log('   ‚úì EU AI Act export\n');

  // ============================================================================
  // SUMMARY
  // ============================================================================
  console.log('‚ïê'.repeat(60));
  console.log('DEMO COMPLETE');
  console.log('‚ïê'.repeat(60) + '\n');

  console.log('What was demonstrated:');
  console.log('  ‚Ä¢ Created a ledger with FINRA 4511 and EU AI Act compliance');
  console.log('  ‚Ä¢ Logged 3 model calls with token counts and costs');
  console.log('  ‚Ä¢ Logged 1 tool invocation (weather API)');
  console.log('  ‚Ä¢ Logged 1 decision point (tool selection)');
  console.log('  ‚Ä¢ Took 1 state snapshot');
  console.log('  ‚Ä¢ Verified hash chain integrity');
  console.log('  ‚Ä¢ Signed with Ed25519 keys');
  console.log('  ‚Ä¢ Exported to multiple compliance formats\n');

  console.log('Next steps:');
  console.log(`  ‚Ä¢ Verify with CLI: npx ts-node packages/cli/src/index.ts verify ${logPath}`);
  console.log(`  ‚Ä¢ View summary: npx ts-node packages/cli/src/index.ts summary ${logPath}`);
  console.log(`  ‚Ä¢ Replay session: npx ts-node packages/cli/src/index.ts replay ${logPath}\n`);
}

// Run the demo
runDemo().catch(console.error);
